# ğŸ§  AI ê¸°ë°˜ ìœ í•´ í‘œí˜„ íƒì§€ ë° ìˆœí™” ì‹œìŠ¤í…œ

ì´ í”„ë¡œì íŠ¸ëŠ” í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ë‚´ì˜ ìœ í•´ í‘œí˜„ì„ íƒì§€í•˜ê³ , GPT APIë¥¼ í™œìš©í•´ **ìì—°ìŠ¤ëŸ½ê³  ì •ì œëœ í‘œí˜„**ìœ¼ë¡œ ë°”ê¾¸ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
src/
â”œâ”€â”€ inference/                  â† ëª¨ë¸ ì¶”ë¡  ëª¨ë“ˆ (í…ìŠ¤íŠ¸/ì´ë¯¸ì§€/ì‚¬ì „ ê¸°ë°˜)
â”œâ”€â”€ prompts/                    â† í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë³´ê´€
â”œâ”€â”€ replace.py                  â† ìœ í•´ í‘œí˜„ ê°ì§€ + GPT ìˆœí™” ì²˜ë¦¬
â”œâ”€â”€ sample_detection.py         â† íƒì§€ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ìš© ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ sample_replacement.py       â† ìˆœí™” ê²°ê³¼ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ ì„¤ì¹˜ ë°©ë²•

1. Python 3.10 ì´ìƒ ì‚¬ìš© ê¶Œì¥
2. ê°€ìƒí™˜ê²½ì„ ë§Œë“  ë’¤, ì•„ë˜ ëª…ë ¹ì–´ë¡œ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.

```bash
pip install -r requirements.txt
```

> âš ï¸ ì£¼ì˜: `torch` ë²„ì „ì€ CUDA í™˜ê²½ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
> GPU ì‚¬ìš© ì‹œ, ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  


---

## ğŸ’¾ ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ë°°ì¹˜

### âœ… í…ìŠ¤íŠ¸ ëª¨ë¸ (RoBERTa ê¸°ë°˜ ë‹¤ì¤‘ ë¶„ë¥˜)

- ë‹¤ìš´ë¡œë“œ: [txt model](https://drive.google.com/file/d/1lXj6CXd2GbhELbti6nxVSg8-Y609Ea-w/view?usp=sharing)
- ì••ì¶• í•´ì œ í›„ â†’ ì•„ë˜ ê²½ë¡œì— ì €ì¥:

```
inference/text/model/
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin
â”œâ”€â”€ tokenizer_config.json
â”œâ”€â”€ vocab.json
â””â”€â”€ ...
```

---

### âœ… ì´ë¯¸ì§€ ëª¨ë¸ (TorchScript í¬ë§·)

- ë‹¤ìš´ë¡œë“œ: [image model](https://drive.google.com/file/d/1fz5P6DDL4hhWwJJbsxfX_zYu13h5nhFz/view?usp=sharing)
- `.ts.pt` ë° `.json` íŒŒì¼ì„ ì•„ë˜ ê²½ë¡œì— ì €ì¥:

```
inference/image/
â”œâ”€â”€ model_ts.pt
â”œâ”€â”€ model_ts.json
```

---

## âš™ï¸ ì‚¬ìš© ë°©ë²•

### ğŸ” ìœ í•´ í‘œí˜„ íƒì§€ (í…ìŠ¤íŠ¸/ì‚¬ì „ ê¸°ë°˜)

```bash
python src/sample_detection.py
```

- `inference/dictionary/`ì— ì •ì˜ëœ ìœ í•´ ë‹¨ì–´ ê¸°ë°˜ ê°ì§€
- `inference/text/`ëŠ” í•™ìŠµëœ ëª¨ë¸ ê¸°ë°˜ íŒë‹¨ (ex. abuse, sexual, violence ë“±)

---

### ğŸª„ ìœ í•´ í‘œí˜„ ìˆœí™” (GPT ê¸°ë°˜)

```bash
python src/sample_replacement.py
```

- `replace_text(text)` í•¨ìˆ˜ í˜¸ì¶œ ì‹œ OpenAI APIë¥¼ í†µí•´ ì •ì œëœ í‘œí˜„ ë°˜í™˜
- `prompts/replace_template.txt`ì—ì„œ ë¬¸ì²´/ì–´íˆ¬ í…œí”Œë¦¿ì„ ììœ ë¡­ê²Œ ì„¤ì • ê°€ëŠ¥

---

## ğŸ“¦ ì£¼ìš” í•¨ìˆ˜ ì„¤ëª…

### 1. `replace_text(text: str, model="gpt-4o-mini", show_prompt=False) -> str`

- ìœ í•´ í‘œí˜„ì´ ê°ì§€ëœ ê²½ìš° GPTë¡œ ìˆœí™”ëœ ë¬¸ì¥ì„ ë°˜í™˜
- ì•„ë¬´ ë¬¸ì œ ì—†ìœ¼ë©´ ì›ë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
- `show_prompt=True`ë¡œ ì„¤ì • ì‹œ, GPTì— ì „ë‹¬ë˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ í™•ì¸ ê°€ëŠ¥

```python
from replace import replace_text
replace_text("ì•¼ì´ ê°œìŒ”ë¼ì•¼", show_prompt=True)
```

---

### 2. `TextPredictor`, `DictionaryChecker` ì§ì ‘ ì‚¬ìš©

```python
from inference.text import TextPredictor
from inference.dictionary import DictionaryChecker

txt_pred = TextPredictor("inference/text/model")
checker = DictionaryChecker("inference/dictionary/dictionary.csv")

print(txt_pred("ìœ í•´ í…ìŠ¤íŠ¸"))
print(checker("ìœ í•´ í…ìŠ¤íŠ¸"))
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

- `sample_detection.py` : ìœ í•´ í‘œí˜„ íƒì§€ ì†ë„/ê²°ê³¼ í™•ì¸
- `sample_replacement.py` : ìˆœí™” ê²°ê³¼ í…ŒìŠ¤íŠ¸ìš©

---

## ğŸ” OpenAI API Key ì„¤ì •

GPT ê¸°ë°˜ ìˆœí™” ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ OpenAI API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤:

```bash
export OPENAI_API_KEY=your_openai_key_here
```

ë˜ëŠ” Python ì½”ë“œì—ì„œ ì§ì ‘ ì„¤ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:

```python
import os
os.environ["OPENAI_API_KEY"] = "your_key_here"
```

---

## ğŸ¤– ì§€ì› ëª¨ë¸

ì•„ë˜ OpenAI GPT ëª¨ë¸ë“¤ê³¼ í˜¸í™˜ë©ë‹ˆë‹¤:

- `gpt-4o`, `gpt-4o-mini`, `gpt-4.1-mini` ë“±

ì‘ë‹µì€ ì•„ë˜ í˜•ì‹ ì¤‘ í•˜ë‚˜ë¡œ ì œê³µë©ë‹ˆë‹¤:

- ì •ì œëœ ë‹¨ì¼ ë¬¸ì¥
- ë˜ëŠ” JSON í˜•ì‹ ê²°ê³¼ (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •ì— ë”°ë¦„)

---
